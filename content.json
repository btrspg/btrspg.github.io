{"meta":{"title":"Big Bang","subtitle":"","description":"Now I am a bioinformatics PhD candidate of CUHK, and used to be a bioinformatics engineer in several companies, Annoroad, Acordx, Oumeng and Aegicare.","author":"Logan","url":"http://btrspg.github.io","root":"/"},"pages":[{"title":"aboutme","date":"2020-08-07T01:54:29.000Z","updated":"2020-08-12T02:46:05.816Z","comments":true,"path":"aboutme/index.html","permalink":"http://btrspg.github.io/aboutme/index.html","excerpt":"","text":"我现在就读于香港中文大学，主要做生物信息，研究方向是non-conding RNA相关调控。在这之前，都是在公司做生物信息相关分析工作。 现在的目标只有一个，就是作出自己想要忘我投入的课题，然后用这个课题顺利毕业。"},{"title":"categories","date":"2020-08-07T01:54:05.000Z","updated":"2020-08-12T02:46:05.816Z","comments":true,"path":"categories/index.html","permalink":"http://btrspg.github.io/categories/index.html","excerpt":"","text":"这个page其实主要是给自己来看，做积累之用。 生物信息相关积累 英文写作积累 随笔"},{"title":"tags","date":"2020-08-07T01:54:37.000Z","updated":"2020-08-12T02:46:05.816Z","comments":true,"path":"tags/index.html","permalink":"http://btrspg.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"hdf5格式到底是什么","slug":"hdf5","date":"2020-08-10T03:52:38.000Z","updated":"2020-08-12T02:46:05.816Z","comments":true,"path":"2020/08/10/hdf5/","link":"","permalink":"http://btrspg.github.io/2020/08/10/hdf5/","excerpt":"","text":"Hierarchical Data Format：HDF 设计用来存储和组织大量数据的一组文件格式（HDF4，HDF5）。它最初开发于美国国家超级计算应用中心，现在由非营利社团HDF Group支持，其任务是确保HDF5技术的持续开发和存储在HDF中数据的持续可访问性。伴随着这个目标，HDF库和相关工具可在自由的类BSD许可证下获得用于一般使用。HDF被很多商业和非商业软件平台所支持，包括Java、MATLAB、Scilab、Octave、Mathematica、IDL、Python, R, Fortran和Julia。可免费获得的HDF发行中包括了库，命令行实用程序，测试包源代码，Java接口，和基于Java的HDF查看器（HDFView） From wikipedia 首先我们可以理解为HDF5是一种文件架构，他主要规定了命名为.hdf5（拓展名包括：.hdf, .h4, .hdf4, .he2, .h5, .hdf5, .he5）这种格式的文件应该遵许一个什么样的规则。就像如果一个文件如果是SAM格式，那他就应该包含11列，第一列是read name，第二列包含什么信息，第三列等等，而且这些列必须是以tab分割。这样其他人看到知道这个文件格式的时候，就知道自己需要的信息从哪里去提取。 所以想要搞明白HDF5就是要搞明白这种文件格式的具体结构。 HDF5 因为目前最常用的就是HDF5，所以这里主要说明这种格式，HDF4忽略不谈。 HDF5只包含两种主要的对象类型： 数据集（datasets），它是同质类型的多维数组；From wikipedia 群组（groups），它是持有数据集和其他群组的容器结构。From wikipedia 群组（group） 群组（group）中可以包含0个或者多个HDF5对象，以及一些元数据（metadata），换句话说，就是group可以包含和自己一样是group类型的数据。 image from CSDN:https://blog.csdn.net/Mrhiuser/article/details/69603826 数据集（datasets） 数据集（datasets）则包含一个多维数组及这个数组的元数据 image from CSDN: https://blog.csdn.net/Mrhiuser/article/details/69603826 应用 因为我最近是因为nanopore的项目才注意到这个文件格式，所以我会以nanopore的原始数据来作为一个例子来说明具体的操作，但是应该会留在之后来具体说明。至此，我们大概了解了这种格式是一个什么样的格式。","categories":[{"name":"一般知识","slug":"一般知识","permalink":"http://btrspg.github.io/categories/%E4%B8%80%E8%88%AC%E7%9F%A5%E8%AF%86/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://btrspg.github.io/tags/linux/"},{"name":"hdf5","slug":"hdf5","permalink":"http://btrspg.github.io/tags/hdf5/"}]},{"title":"Deep learning enables accurate clustering with batch effect removal in single-cell RNA-seq analysis","slug":"Deep-learning-enables-accurate-clustering-with-batch-effect-removal-in-single-cell-RNA-seq-analysis","date":"2020-08-07T08:14:22.000Z","updated":"2020-08-12T02:46:05.816Z","comments":true,"path":"2020/08/07/Deep-learning-enables-accurate-clustering-with-batch-effect-removal-in-single-cell-RNA-seq-analysis/","link":"","permalink":"http://btrspg.github.io/2020/08/07/Deep-learning-enables-accurate-clustering-with-batch-effect-removal-in-single-cell-RNA-seq-analysis/","excerpt":"","text":"[TOC] 单细胞测序的数据是越来越多，随之而来的一些困难也逐渐明显，对于大量非同批次的单细胞数据直接分析，可能分析的结果都是批次效应导致的偏差结果。而这篇文章所发布的软件，就是利用deep learning来解决这一难题，DESC通过逐步训练来逐步消除批次效应。作者展示了该方法在不同数据上均能展示良好的性能，下面就来一起看看。 Workflow 整个工作流程不算特别的复杂。 DESE的clustering是基于autoencoder的bottleneck nodes来做的，根据这些（降维了的）bottleneck节点作为特征来聚类样本，调整参数，从而最终达到去除批次效应的目的。 批次效应 被称为批次效应的影响因素其实很多，并不简简单单的就是我的实验批次（例如这批数据我分几个时间段做的，这不同的时间段就是不同批次）。如下面这批数据所描述的恒河猴视网膜数据一样，来自不同的恒河猴（animal level），来自不同的区域（region level），以及这两个的综合因素（sample level）都算是具有批次效应的因素。这些都会影响到我们后续的单细胞分析中。 不同数据结果展示 恒河猴视网膜数据 图中b 表示按照动物的来源（共四只恒河猴）进行标注，可以看出通过DESC去除批次效应后，不同来源的细胞并没有独立出来，而是很好的混合到了一起。图中c 表示按照样本信息（样本+区域）进行标注，图中d 表示按照细胞来源区域进行标注（视网膜凹处，视网膜周围），可以看出来除了有两个聚类是包含大量视网膜外周细胞以外，其他聚类均为混合细胞。 DESC还有一个很大的优势则是，他可以不同给定batch信息，就能够直接去除batch effect，如上图e中所展示，ARI是描述聚类正确性的指标（以后会专门介绍），不同的颜色表示以不同的批次信息为去除批次效应的参数。从上图可以看出，除了DESC及scVI，其他的算法均需要用户给定批次信息才能做到去除批次效应。而scVI即便可以不用提供批次信息就能直接去除批次效应，但是效果却并不好。从中可以看出，DESC是效果最好的，而且当批次的信息为sample的时候（也就是认为批次最多的时候），性能是最好的。（图中的ALL就表示不给出批次信息，盲去） 而用KL divergence（后面也会详细介绍）来判断新能差异，同样能看出，DESC在给定批次信息，不同批次信息及不给定批次信息的去批次效应的效果都是最好的。 在此列出了其他算法在基于region的批次效应去除时的效果，可以看出其他算法有大量的clusters是只包含有一种区域来源细胞的，可见批次效应并没有很好的去除。 这时，作者比较了DESC和scVI这两个可以不提供批次信息的算法，上图中的顶部DESC的结果，底部是scVI结果，可以很明显的看出，即便没有给出批次信息，DSCE也能很好的将批次效应去除，而对于scVI，结果上就不那么令人满意了。 不同protocols的胰岛数据 作者找了4个来自不同实验protocols的胰岛数据，来将其合并分析，去除他们之间的批次效应（不同实验方法） Fluidigm C1 SMART-seq2 CEL-seq CEL-seq2 结果如下： 可以从上图看出，除了DESC,Seurat3.0,CCA以外，其他的算法并不能将它们之间的批次效应很好的去除，而且即便是Seurat3.0这样看上去还不错的算法，一些显著的 α\\alphaα 细胞和β\\betaβ细胞分到了一块，说明结果只是差强人意。 我们可以从上图中发现，DESC是逐步将批次效应去除的。 外界刺激的外周血细胞 这套数据的实验目的就需要好好解释一下。所有的算法在去除批次效应的时候都会害怕去除的太厉害，会不会将我们需要看到的生物学差异也给去除掉了。而在前面几套数据中，我们已经看到了DESC在去除批次效应上的卓越成效，那他会不会是牺牲了很多生物学差异的去除呢，如果是这样，那就得不偿失了。 所以作者找到另一套数据来说明这个问题，说明自己的算法仅仅是去除了批次效应，生物学差异仍旧很好的保留着。 作者直接找到了8个样本的外周血细胞，并且一部分作为control，另一部分使用interferon-beta进行刺激。这就相当于保证了批次信息一样，但是实验条件不同。 这样的数据的结果如上图，除了两个clusters，其他的clusters中都是两类细胞均有，而通过上图中的b图发现，这两个clusters是CD14+ monocytes. 通过差异表达分析可以看出CD14+ monocytes细胞case与control的差异是其他类细胞的很多倍差异。而且之前的研究也表明了，这种细胞在收到刺激后，的确会发生很大的变化，所以将其划分为两个clusters也是没有问题的。 可见DESC可以去除批次效应，而且并不会影响到本身的生物学差异。 老鼠骨髓先祖细胞 单细胞数据还会经常用来做细胞分化的研究，作者使用一套老师的骨髓先祖细胞数据来证明自己的算法并不会影响这一类的分析。 这里需要注意的是上图中的a图，这个图的颜色是根据分类的得分来的，而我们可以发现，分化越厉害的细胞，分类得分越高，所以这个得分也是有生物学意义的。 单核细胞 这个就是主要针对于连续状态细胞进行聚类 上图中表示三个批次的结果，发现只有DESC的结果对于三个批次的细胞时间序列是一致的，并不随着批次的变化而变化。因为上图中的所有数据都来自健康人的外周血，所以应该不会有显著变化，对于其他的结果则明显看出，不同批次的时间序列结果是有差异的。 性能 性能的结果就非常明显的提升，不仅在正确率上有显著的提升，内存消耗也减少了，还支持GPU。 写在最后 里面还有一些细节并没有搞的特别清楚，还是需要继续研究，不过对于这个软件觉得可玩性还是挺高的。","categories":[],"tags":[{"name":"bioinformatics","slug":"bioinformatics","permalink":"http://btrspg.github.io/tags/bioinformatics/"},{"name":"single-cell RNA-seq","slug":"single-cell-RNA-seq","permalink":"http://btrspg.github.io/tags/single-cell-RNA-seq/"},{"name":"batch effect","slug":"batch-effect","permalink":"http://btrspg.github.io/tags/batch-effect/"},{"name":"deep learning","slug":"deep-learning","permalink":"http://btrspg.github.io/tags/deep-learning/"},{"name":"literature","slug":"literature","permalink":"http://btrspg.github.io/tags/literature/"}]},{"title":"ExpressionSet","slug":"ExpressionSet","date":"2020-03-01T12:28:25.000Z","updated":"2020-08-12T02:46:05.816Z","comments":true,"path":"2020/03/01/ExpressionSet/","link":"","permalink":"http://btrspg.github.io/2020/03/01/ExpressionSet/","excerpt":"有没有试过，之前完成的项目再次需要进一步处理的时候，发现之前存的数据完全想不起来包含的是什么内容，特别是涉及到临床信息，写了一个case/control，却完全没有注明，case是什么，control是什么。 近段时间看到一些非常棒的R包（以后可能会分享），发现很多R包的数据输入格式是一个叫做ExpressionSet的我从来没有接触过的格式。为了使用那些非常棒的R包，不得不又去看了这个ExpressionSet的数据格式，没想到被我看到了一个_又老又非常棒的R包_。","text":"有没有试过，之前完成的项目再次需要进一步处理的时候，发现之前存的数据完全想不起来包含的是什么内容，特别是涉及到临床信息，写了一个case/control，却完全没有注明，case是什么，control是什么。 近段时间看到一些非常棒的R包（以后可能会分享），发现很多R包的数据输入格式是一个叫做ExpressionSet的我从来没有接触过的格式。为了使用那些非常棒的R包，不得不又去看了这个ExpressionSet的数据格式，没想到被我看到了一个_又老又非常棒的R包_。 以下是官方的介绍： The ExpressionSet class is designed to combine several diﬀerent sources of information into a single convenient structure. An ExpressionSet can be manipulated (e.g., subsetted, copied) conveniently, and is the input or output from many Bioconductor functions. 也就是能够将多种信息整合到一个数据结构中，而且这种数据结构还非常方便进行各种操作。 到这里，它已经有二点点的吸引我了（之前的一点点就是我必须要用它），让我了解下它到底能干什么。原来它之前主要是针对于microarray的数据存储来设计的，它包含了多个成分，分别是assayData,phenoData,featureData,annotation和experimentData。其中最常用的就是assayData和phenoData，分别表示了表达矩阵和表型信息（也可以理解成样本的临床信息）。 下面我就来介绍一下，怎么将一般的数据转化为ExpressionSet以及转化成ExpressionSet之后能做什么。 安装 因为ExpressionSet并不是R中自带，所以必须安装，在R3.5以上版本，只需要如下命令即可。 123if (!require(&quot;BiocManager&quot;)) install.packages(&quot;BiocManager&quot;)BiocManager::install(&quot;Biobase&quot;) 使用 1library(Biobase) 导入该R包，下面我用一个例子来具体说明。假设我们现在有一个表达矩阵数据，存在一个CSV格式的文件里，以及该表达矩阵中所涉及样本的临床信息，同样也存在一个CSV的文件中。 表达矩阵（demoExpression.csv）如下： sample1 sample2 sample3 sample4 gen1 0.76952238 0.36663781 0.79340003 0.6260257 gen2 0.91780668 0.37357912 0.5480497 0.0542586 gen3 0.1108848 0.28149705 0.46075876 0.47926737 gen4 0.179007 0.98929444 0.21465441 0.66763618 gen5 0.83170474 0.86364345 0.1785267 0.98886996 gen6 0.68540221 0.78312865 0.70104657 0.25904827 gen7 0.99732179 0.71879339 0.44494156 0.4203282 临床信息（demoClinicalInfo.csv）如下： Sample Type Age Gender sample1 Case 18 F sample2 Case 33 M sample3 Case 24 F sample4 Case 35 F sample5 Case 56 F sample6 Case 44 F sample7 Case 39 F sample8 Case 60 M sample9 Control 42 M sample10 Control 23 M 我们正在使用read.csv即可读入这些数据 1234567# 表达矩阵exp_demo=as.matrix(read.csv(&#x27;demoExpression.csv&#x27;,quote=&#x27;&#x27;,row.names=1))# 临床信息info_demo=read.csv(&#x27;demoClinicalInfo.csv&#x27;,quote=&#x27;&#x27;,row.names=1)# 检查是否样本对应all(rownames(info_demo)==colnames(exp_demo))# TRUE 读入数据之后，其实非常容易就可以得到ExpressionSet 12first_expressionSet = ExpressionSet(assayData=exp_demo) # 将exp_demo直接赋给assayDatafirst_expressionSet 输出如下： 12345678ExpressionSet (storageMode: lockedEnvironment)assayData: 34 features, 15 samples element names: exprs protocolData: nonephenoData: nonefeatureData: noneexperimentData: use &#39;experimentData(object)&#39;Annotation: 可以从中看出，该ExpressionSet数据中，只有assayData被赋予了值，而且能看出统计信息，例如34 features（有34个基因），15 samples（15个样本）。 在此我们就完成了最基本的，将基因表达谱装到ExpressionSet中，下面就轮到临床信息了，但在处理临床信息之前，需要说明一点，就是每当我们从别处获得临床信息，或者将要把临床信息传递出去的时候，是不是就像上表中的我一样，以这种表格。 Sample Type Age Gender sample1 Case 18 F 这种临床信息较为简单，几乎看到表头，我们就能知道里面的信息是什么（当然也有含糊的地方，这个TYPE中的case到底是什么，我能理解是处理组，但是什么处理能写出来吗？） 而将这样的临床信息补充完整，将对我们传递数据，或者许久以后我们再来处理这些数据回想信息将会有非常大的帮助。 12345# 该data frame中，必须要有labelDescriptionmetadata &lt;- data.frame(labelDescription=c(&quot;patient type, case means liver cancer sample and control means while cells sample&quot;, &quot;age&quot;, &quot;gender, F=Female M=Male&quot;), row.names=c(&quot;Type&quot;, &quot;Age&quot;, &quot;Gender&quot;)) 在此相当于给我们的临床信息的表头建立了一个meta数据，我们也会将其一块存入ExpressionSet，这样我们以后打开ExpressionSet，信息一目了然。 我们首先将临床信息和对应的meta信息放入一个新的AnnotatedDataFrame 123phenoData &lt;- new(&quot;AnnotatedDataFrame&quot;, data=info_demo, varMetadata=metadata)phenoData 输出如下： 1234An object of class &#39;AnnotatedDataFrame&#39; rowNames: sample1 sample2 ... sample15 (15 total) varLabels: Type Age Gender varMetadata: labelDescription 有了这样的数据，我们就可以将临床信息和表达数据整理到一起了 123exampleSet &lt;- ExpressionSet(assayData=exp_demo, phenoData=phenoData)exampleSet 现在我们的ExpressionSet信息就更加丰富了。 1234567891011ExpressionSet (storageMode: lockedEnvironment)assayData: 34 features, 15 samples element names: exprs protocolData: nonephenoData sampleNames: sample1 sample2 ... sample15 (15 total) varLabels: Type Age Gender varMetadata: labelDescriptionfeatureData: noneexperimentData: use &#39;experimentData(object)&#39;Annotation: 里面存了 表达矩阵信息 临床信息及临床信息的描述信息 如果我们想要一个文件代表所有，就可以尽可能的完善所有信息，因为后续的并不是每个都能用得上所以，我会快速过一遍。 12345678910111213141516# 我想加入一些该试验的描述信息，下面用到中文的地方只是为了表示这个位置可以写入信息，最好别用中文。experimentData &lt;- new(&quot;MIAME&quot;, name=&quot;生信小白板&quot;, lab=&quot;自由主义的实验室&quot;, contact=&quot;bioinfo.board@xxxx.com&quot;, title=&quot;Smoking-Cancer Experiment&quot;, abstract=&quot;Biobase is part of the Bioconductor project, and is used by many other packages. Biobase contains standardized data structures to represent genomic data. The ExpressionSet class is designed to combine several diﬀerent sources of information into a single convenient structure. An ExpressionSet can be manipulated (e.g., subsetted, copied) conveniently, and is the input or output from many Bioconductor functions.&quot;, url=&quot;www.lab.not.exist&quot;, other=list( notes=&quot;Created from text files &quot; ))# 将其加入ExpressionSetexampleSet &lt;- ExpressionSet(assayData=exp_demo, phenoData=phenoData, experimentData=experimentData, annotation=&quot;human&quot;)exampleSet 输入如下： 1234567891011ExpressionSet (storageMode: lockedEnvironment)assayData: 34 features, 15 samples element names: exprs protocolData: nonephenoData sampleNames: sample1 sample2 ... sample15 (15 total) varLabels: Type Age Gender varMetadata: labelDescriptionfeatureData: noneexperimentData: use &#39;experimentData(object)&#39;Annotation: human 可以看出如果想知道实验信息，使用experimentData(object) 1experimentData(exampleSet) 输出： 123456789101112Experiment data Experimenter name: &lt;U+751F&gt;&lt;U+4FE1&gt;&lt;U+5C0F&gt;&lt;U+767D&gt;&lt;U+677F&gt; Laboratory: &lt;U+81EA&gt;&lt;U+7531&gt;&lt;U+4E3B&gt;&lt;U+4E49&gt;&lt;U+7684&gt;&lt;U+5B9E&gt;&lt;U+9A8C&gt;&lt;U+5BA4&gt; Contact information: bioinfo.board@xxxx.com Title: Smoking-Cancer Experiment URL: www.lab.not.exist PMIDs: Abstract: A 1 word abstract is available. Use &#39;abstract&#39; method. notes: notes: Created from text files 所以其中的中文都会被如此处理，我们同样可以查看详细的摘要信息 1cat(abstract(exampleSet)) Biobase is part of the Bioconductor project, and is used by many other packages. Biobase contains standardized data structures to represent genomic data. The ExpressionSet class is designed to combine several di&lt;U+FB00&gt;erent sources of information into a single convenient structure. An ExpressionSet can be manipulated (e.g., subsetted, copied) conveniently, and is the input or output from many Bioconductor functions. 这样一个完整的数据集，拿到哪，我都能知道它包含什么样的数据，什么样的信息。所以我会将他保留下来，替代我并不完整的两个CSV文件 1saveRDS(exampleSet, file = &quot;demo.rds&quot;) 如果想要要读取也很简单 1readRDS(&#x27;demo.rds&#x27;) 下面给大家看一点小信息，那就是用这种方法存储数据，所占内存更小。 123-rw-rw-r-- 1 xxx xxx 322 Mar 1 16:04 demoClinicalInfo.csv-rw-rw-r-- 1 xxx xxx 6383 Mar 1 16:04 demoExpression.csv-rw-r--r-- 1 xxx xxx 5562 Mar 1 18:54 demo.rds 后话 为什么我会觉得了解到这个挺不错 第一，很多的R包都支持这样一种格式，如果想要使用很多R包，了解他的输入那是必须的 第二，就是他真的让我觉得非常全面，可以将所有信息存放到一起，即便很长时间后，我也不会因为我自己的疏忽而不知道什么数据是干什么，只要我在最开始生成这个文件的时候耐心一点。 第三，该数据结构同样可以进行数据切片和筛选，和一般的data.frame操作无异。 如果想了解完整例子，可以看https://github.com/btrspg/examples-in-bb/blob/master/ExpressionSet/example.ipynb","categories":[{"name":"中文","slug":"中文","permalink":"http://btrspg.github.io/categories/%E4%B8%AD%E6%96%87/"}],"tags":[{"name":"bioinformatics","slug":"bioinformatics","permalink":"http://btrspg.github.io/tags/bioinformatics/"},{"name":"R","slug":"R","permalink":"http://btrspg.github.io/tags/R/"}]},{"title":"Grokking-Algorithms","slug":"Grokking-Algorithms","date":"2020-02-04T14:22:52.000Z","updated":"2020-08-12T02:46:05.816Z","comments":true,"path":"2020/02/04/Grokking-Algorithms/","link":"","permalink":"http://btrspg.github.io/2020/02/04/Grokking-Algorithms/","excerpt":"","text":"《算法图解》是通过别人推荐的非常入门的算法书籍，对于比较熟悉算法的可能觉得比较浪费时间，而对于我这种，想要入门的那真是很不错的。里面有一些老知识，也能够获得一些新的知识，我想主要目的，还是让人觉得算法可以从简单的开始，并不是完全不明白的。 其中我印象最深的要数hash了，这个从perl的my %hash;一直用到python的mydict=dict()却一直理解错了他的意思。 原来他是通过hash函数，将一个key值进行转化成index，然后在hash表中使用该index进行存储value，这样他就能够很快的插入及存储数据了，这也就是为什么hash的存储及访问都非常的快的原因。第一次明白的时候不得不佩服，这个想法真的非常厉害。","categories":[{"name":"中文","slug":"中文","permalink":"http://btrspg.github.io/categories/%E4%B8%AD%E6%96%87/"}],"tags":[{"name":"bioinformatics","slug":"bioinformatics","permalink":"http://btrspg.github.io/tags/bioinformatics/"},{"name":"算法图解","slug":"算法图解","permalink":"http://btrspg.github.io/tags/%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3/"},{"name":"读后感","slug":"读后感","permalink":"http://btrspg.github.io/tags/%E8%AF%BB%E5%90%8E%E6%84%9F/"}]},{"title":"Conda打造‘完美’分析环境","slug":"conda-build-perfect-environment","date":"2019-09-13T09:34:48.000Z","updated":"2020-08-12T02:46:05.816Z","comments":true,"path":"2019/09/13/conda-build-perfect-environment/","link":"","permalink":"http://btrspg.github.io/2019/09/13/conda-build-perfect-environment/","excerpt":"Conda 能用来干什么相信大家已经非常清楚了，几乎所有使用python的小伙伴都会或多或少的使用到conda来帮助做不同版本环境的控制。 有时甚至会将整个分析环境都打包到一个conda环境中，所以用Conda打造‘完美’分析环境似乎没有什么新意。 但是我这里说到的‘完美’是利用Conda还要加上jupyter lab来共同打造。 在自己的电脑上使用jupyter lab和conda有什么好说的 那我就先放一张图，看看是否有些吸引力","text":"Conda 能用来干什么相信大家已经非常清楚了，几乎所有使用python的小伙伴都会或多或少的使用到conda来帮助做不同版本环境的控制。 有时甚至会将整个分析环境都打包到一个conda环境中，所以用Conda打造‘完美’分析环境似乎没有什么新意。 但是我这里说到的‘完美’是利用Conda还要加上jupyter lab来共同打造。 在自己的电脑上使用jupyter lab和conda有什么好说的 那我就先放一张图，看看是否有些吸引力 熟悉的jupyter lab界面，不过似乎有一些不太一样，不仅仅有python，还有R，还有新兴的数据分析黑马julia。 以往jupyter lab 以往jupyter lab 安装在自己笔记本或者台式上时，总觉得有些性能吃紧，想要试试分析大点的数据就吃不消，所以有条件当然是放到SERVER上，然后本地访问，这样既能保证操作方便，计算还得心应手。 顺便说一下自己的情况，因为是刚开始操作，所以准备将jupyter lab配置在登陆节点（60G内存，只是用来做登陆管理节点太浪费了），计算节点还是老老实实的做计算。 为了不让整个过程过于枯燥，先将结果放上来，展示一下。 配置后结果 服务器端启动 客户端使用情况 说明：所有涉及到code的部分，均来自于网上教程，文末给出链接 用python画画图 用Julia画个图 用R画个图 环境下安装软件 因为是基于conda的环境，所以想装任何软件，简单方便 说明：使用‘!’来执行shell命令只能在python的环境下使用，julia和R kernel均不支持。 用这个界面来画个图，做做小分析，做个测试，是不是开心愉快。下面详细说说整个配置过程。 配置 安装conda，教程 生成一个新的conda环境，conda create -n &lt;name&gt; python=3.5 激活conda环境，conda activate &lt;name&gt; 安装所有必须的软件及包，conda install -y -c conda-forge jupyterlab julia r-irkernel 生成jupyter配置文件，jupyter notebook --generate-config 安装IJulia,julia&gt;;Pkg;add IJulia;build IJulia 根据自己配置需求修改jupyter配置文件，详细给参照说明 修改完成后，启动即可，jupyter lab --ip 0.0.0.0 整个过程不算麻烦，就是内地的网络有的时候在配置时会有些影响，如果这样还是认为麻烦，那我就只能拿出我的杀手锏了。 有一个已经写好的docker image，在服务器上pull下来，即可直接使用。 Docker image 123docker run --rm -it -p 8888:9000 \\ -v `pwd`:/lab/works btrspg/jupyterlab:1.0.0 \\ bash -c &#x27;jupyter lab --ip 0.0.0.0 --allow-root&#x27; 其中的pwd修改成项目所在目录即可，这样在自己的电脑上，只用输入服务器ip:8888即可。 自己的项目所有文件均会在jupyter lab的works目录下 想要安装新的包？想有自己的image？ 123FROM btrspg/jupyterlabRUN conda install -r anaconda bioconductor-deseq2 然后build一个新的image即可。 最后希望大家玩得开心，中秋快乐！","categories":[{"name":"中文","slug":"中文","permalink":"http://btrspg.github.io/categories/%E4%B8%AD%E6%96%87/"}],"tags":[{"name":"bioinformatics","slug":"bioinformatics","permalink":"http://btrspg.github.io/tags/bioinformatics/"},{"name":"anaconda","slug":"anaconda","permalink":"http://btrspg.github.io/tags/anaconda/"},{"name":"jupyter notebook","slug":"jupyter-notebook","permalink":"http://btrspg.github.io/tags/jupyter-notebook/"}]}],"categories":[{"name":"一般知识","slug":"一般知识","permalink":"http://btrspg.github.io/categories/%E4%B8%80%E8%88%AC%E7%9F%A5%E8%AF%86/"},{"name":"中文","slug":"中文","permalink":"http://btrspg.github.io/categories/%E4%B8%AD%E6%96%87/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://btrspg.github.io/tags/linux/"},{"name":"hdf5","slug":"hdf5","permalink":"http://btrspg.github.io/tags/hdf5/"},{"name":"bioinformatics","slug":"bioinformatics","permalink":"http://btrspg.github.io/tags/bioinformatics/"},{"name":"single-cell RNA-seq","slug":"single-cell-RNA-seq","permalink":"http://btrspg.github.io/tags/single-cell-RNA-seq/"},{"name":"batch effect","slug":"batch-effect","permalink":"http://btrspg.github.io/tags/batch-effect/"},{"name":"deep learning","slug":"deep-learning","permalink":"http://btrspg.github.io/tags/deep-learning/"},{"name":"literature","slug":"literature","permalink":"http://btrspg.github.io/tags/literature/"},{"name":"R","slug":"R","permalink":"http://btrspg.github.io/tags/R/"},{"name":"算法图解","slug":"算法图解","permalink":"http://btrspg.github.io/tags/%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3/"},{"name":"读后感","slug":"读后感","permalink":"http://btrspg.github.io/tags/%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"name":"anaconda","slug":"anaconda","permalink":"http://btrspg.github.io/tags/anaconda/"},{"name":"jupyter notebook","slug":"jupyter-notebook","permalink":"http://btrspg.github.io/tags/jupyter-notebook/"}]}